# Day 45

Done: Yes
Topic: API, Scrapping
Languages: Python
Difficulty: ⭐⭐⭐
Date Started: June 28, 2023
Date Completed: June 28, 2023

## What I Learned Today

Add /robots.txt  at any link to look what you can not scrape data from

## Key Concepts

- concept 1....

### Quick Links

---

[**google.com**](http://www.google.com)

[**stackoverflow.com**](http://www.stackoverflow.com)

[**w3Schools.com**](https://www.w3schools.com/)

[**github.com**](https://github.com/)

## Local website scrapping

```python
# MAIN.PY

from bs4 import BeautifulSoup
# import lxml

with open("website.html", encoding="utf8") as website:
    contents = website.read()

soup = BeautifulSoup(contents, "html.parser") # lxml
#print(soup.prettify()) #the hole html #prettify to make it nicer
#print(soup.title) #tag
#print(soup.title.name) #name of tag
#print(soup.title.string) #string of the tag

# get al anchortags

all_anchor_tags = soup.find_all(name="a")
#print(all_anchor_tags)

# Get all values inside

for tag in all_anchor_tags:
    print(tag.getText())
    print(tag.get("href")) # the value you chose

heading = soup.find(name="h1",  id="name") #Find particular element
print(heading)

section_heading = soup.find(name="h3", class_="heading")
print(section_heading)
#print(section_heading.text)
#print(section_heading.name)

# Navigate HTML
company_url = soup.select_one(selector="p a") # first match, select will give you all matches
print(company_url.get("href"))

headings = soup.select(".heading") #class heading
print(headings)

# WEBSITE.HTML

<!DOCTYPE html>
<html>

<head>
	<meta charset="utf-8">
	<title>Angela's Personal Site</title>
</head>

<body>
	<h1 id="name">Angela Yu</h1>
	<p><em>Founder of <strong><a href="https://www.appbrewery.co/">The App Brewery</a></strong>.</em></p>
	<p>I am an iOS and Web Developer. I ❤️ coffee and motorcycles.</p>
	<hr>
	<h3 class="heading">Books and Teaching</h3>
	<ul>
		<li>The Complete iOS App Development Bootcamp</li>
		<li>The Complete Web Development Bootcamp</li>
		<li>100 Days of Code - The Complete Python Bootcamp</li>
	</ul>
	<hr>
	<h3 class="heading">Other Pages</h3>
	<a href="https://angelabauer.github.io/cv/hobbies.html">My Hobbies</a>
	<a href="https://angelabauer.github.io/cv/contact-me.html">Contact Me</a>
</body>

</html>
```

## Scrapping YC Hacker News

```python
from bs4 import BeautifulSoup
import requests

response = requests.get("https://news.ycombinator.com/")
yc_website = response.text

soup = BeautifulSoup(yc_website, "html.parser")

title_line = (soup.find_all(name="span", class_="titleline"))
#title_line = title_line.find(name="a")
text = []
link = []
for titles in title_line:
    title = titles.find(name="a")
    text.append(title.getText())
    link.append(title.get("href"))
up_vote = soup.find_all(class_="score")
vote = [int(votes.getText().split(" ")[0]) for votes in up_vote]
sort_vote = sorted(vote, reverse=True)
indexes = [vote.index(i) for i in sort_vote]

for i in indexes:
    print(vote[i])
    print(text[i])
    print(link[i])
    print("\n")

```

## 100 Movies Empire Scrapping

```python

from bs4 import BeautifulSoup
import requests

response = requests.get("https://web.archive.org/web/20200518073855/https://www.empireonline.com/movies/features/best-movies-2/")
empire_website = response.text

soup = BeautifulSoup(empire_website, "html.parser")

page_titles = soup.find_all(name="h3", class_="title")
titles = [title.getText() for title in page_titles]
titles = titles[::-1]

with open("movies.txt", "w") as films:
    for title in titles:
        try:
            films.write(f"{title} \n")
        except:
            films.write(f"{titles.index(title)}) skip\n")

```

## Challenges Experienced

## Resources Used

add resources you used